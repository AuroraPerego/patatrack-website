---
title: "Alpaka support in CMSSW"
author: "Felice Pantaleo"
layout: default
markdown: kramdown
resource: true
categories: jobs-ads
---
### Alpaka support in CMSSW
Designing user-friendly interfaces for common tasks such as memory operations, work divisions optimisation, and kernel launches, to simplify the development of CMS software with Alpaka.
Act as liaison between the CMS Experiment and the Alpaka developers !

The Center for Advanced Systems Understanding unites the partners Helmholtz-Zentrum Dresden – Rossendorf (HZDR), Helmholtz Center for Environmental Research (UFZ), Technische Universität Dresden (Technical University of Dresden – TUD) and Max Planck Institute of Molecular Cell Biology and Genetics (MPI-CBG). This makes it a unique combination of institutes of the Helmholtz Association and the Max Planck Society with the “University of Excellence” Technische Universität Dresden.

The Patatrack team at CERN has a leading role in the exploration of innovative software and hardware technologies to bring smart software closer to the detectors read-out at CERN experiments. 

The Patatrack team has been laying the foundations for the heterogeneous physics reconstruction in CMS since 2016. The challenges of the reconstruction algorithms used by CMS are twofold: they have to achieve a high level of efficiency and accuracy, while meeting the throughput and memory requirements of the experiment's online and offline computing infrastructure. To reach these goals the Patatrack team has been exploring parallel algorithms and heterogeneous reconstruction techniques, and exploiting new architectures such as GPUs and FPGAs. After an initial prototyping, the introduction of a fully heterogeneous reconstruction in the CMS software will leverage portability frameworks.

ALPAKA (Abstraction Library for Parallel Kernel Acceleration) is a header-only C++14 abstraction library for accelerator development. It allows performance portability across different accelerator architectures, providing abstraction for the parallelism and for data management. This will lead to more maintainable software that can be built from a single source and run on different architectures, reducing the maintenance cost and avoiding the need of several implementations of the same algorithm. 
Alpaka and associated libraries are part of the Helmholtz Research Field Matter strategic program oriented funding and specifically dedicated to support data management and analysis in the areas of particle physics, astro particle physics and science with photons, neutrons and ions.

The position is available immediately; applications are considered until the position is filled.
The appointments are initially for one year and renewable annually, subject to mutual satisfaction and to continued CASUS funding.

Extended residence at CERN will be necessary, or frequent travel to CERN if the applicant prefers to be based in Görlitz.

Expressions of interest and CV can be sent to <felice.pantaleo@cern.ch> and <andrea.bocci@cern.ch>.

### Functions:
You will play an important role in the development of the heterogeneous solutions applied to HEP event reconstruction, by holding the following responsibilities:
Design and development of a run-time backend selector in CMSSW.
Simplify the development of CMS software with Alpaka, designing user-friendly interfaces for common tasks such memory operations, work divisions optimisation, kernel launches, etc.
Act as liaison between the CMS Experiment and the Alpaka developers.

### Qualifications: 
Master's degree or PhD or equivalent relevant experience in the field of computing or physics or a related field.

### Experience:
Experience in C++ programming (C++11,14,17).
Experience in implementing and optimizing algorithms on GPUs through CUDA, OpenCL or through abstraction layers (Alpaka, SYCL, Kokkos, etc).
Knowledge and application of software life-cycle tools and procedures: git, JIRA.
Development of application software: object-oriented design and development, parallel programming, algorithm development and optimisation.
